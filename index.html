<!DOCTYPE html>
<html lang="en">

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>COWP Project</title>

    <link rel="stylesheet" type="text/css" href="css/style.css">
    <link href="/css/css" rel="stylesheet" type="text/css">

<body data-gr-c-s-loaded="true" data-new-gr-c-s-check-loaded="14.998.0" data-gr-ext-installed="">
    <link media="all" href="/css/glab.css" type="text/css" rel="StyleSheet">

    <style type="text/css" media="all">
        IMG {
            PADDING-RIGHT: 0px;
            PADDING-LEFT: 0px;
            FLOAT: right;
            PADDING-BOTTOM: 0px;
            PADDING-TOP: 0px
        }

        #primarycontent {
            MARGIN-LEFT: auto;
            WIDTH: expression(document.body.clientWidth > 500? "500px": "auto");
            MARGIN-RIGHT: auto;
            TEXT-ALIGN: left;
            max-width: 850px;
        }

        BODY {
            TEXT-ALIGN: center
        }

    </style>

    <div id="primarycontent">
        <center>
            <h0>Robot Task Planning and Situation Handling in Open Worlds</h0>
        </center>
        <center>
            <p><strong>Yan Ding</strong><sup>1</sup>,&nbsp;Xiaohan Zhang<sup>1</sup>,&nbsp;Saeid Amiri<sup>1</sup>,&nbsp;Nieqing Cao<sup>1</sup>,&nbsp;Hao Yang<sup>2</sup>,<br>&nbsp;Chad Esselink<sup>2</sup>,&nbsp;Shiqi Zhang<sup>1</sup></p>
            <center>
                <p><sup>1</sup>SUNY Binghamton &nbsp;<sup>2</sup>Ford Motor Company</p>
                <center>
<!--                    <p>IEEE RA-L, 2022 </p>-->
                    <p>[<a href='files/COWP_ICRA2023.pdf'>Paper</a>]&nbsp[<a href='files/COWP_Supplementary.pdf'>Supplementary</a>]&nbsp[<a href="https://github.com/yding25/GPT-Planner">Code</a>]&nbsp[<a href="files/COWP_dataset_6tasks.xlsx">Dataset]</a>&nbsp[<a href="https://www.youtube.com/embed/HtxlXSzY5VQ">Demo</a>]
                    </p>

                    <table border="0" cellspacing="10" cellpadding="0" align="center">
                        <tbody>
                            <tr>
                                <td valign="middle" align="center">
                                    <iframe width="500" height="320" src="https://www.youtube.com/embed/HtxlXSzY5VQ" frameborder="0" allowfullscreen></iframe>
                                </td>
                            </tr>
                        </tbody>
                    </table>


                    <h1 align="center">Abstract</h1>
                    <div style="font-size:30px">
                        <p align="justify" width="20%">Automated task planning algorithms have been developed to help robots complete complex tasks that require
                            multiple actions. Most of those algorithms have been developed for “closed worlds” assuming complete world knowledge is provided. However, the real world is generally open, and the robots frequently encounter unforeseen situations that can potentially break the planner’s completeness. This paper introduces a novel algorithm (<b>COWP</b>) and system for open-world task planning and situation handling that dynamically augments the robot’s action knowledge with task-oriented common sense. In particular, common sense is extracted from Large Language Models based on the current task at hand and robot skills. 
                            <!-- For systematic evaluations, we collected a dataset that includes <b>561</b> execution-time situations in a dining domain, where each situation corresponds to a state instance of a robot being potentially unable to complete a task using a solution that normally works. Experimental results show that our approach significantly outperforms competitive baselines from the literature in the success rate of service tasks. Additionally, we have demonstrated COWP using a mobile manipulator.</p> -->
                    </div>

                    <br>

                    <h1 align="center">Contributions</h1>
                    <div style="font-size:30px">
                        <p align="justify" width="20%">The main contribution of this work is <b>a novel integration of a pre-trained LLM with a knowledge-based task planner</b>. Inheriting the desirable features from both sides, COWP is well grounded in specific domains while embracing commonsense solutions at large. </p>
                        <p align="justify" width="20%">
                            For systematic evaluations, we have created a dataset with <b>561</b> execution-time situations collected from a dining domain using a crowd-sourcing platform, where each situation corresponds to an instance of a robot not being able to perform a plan (that normally works). According to experimental results, we see COWP performed significantly better than three literature-selected baselines in success rate. We implemented and demonstrated COWP using a mobile manipulator.</p>
                    </div>

                    <br>

                    <h1 align="center">Framework</h1>
                    <table border="0" cellspacing="10" cellpadding="0" align="center">
                        <td>
                            <img src="./img/fig_cowp.png" style="width:100%;margin-left:0%;margin-right:0%;">
                        </td>
                    </table>

                    <div style="font-size:30px">
                        <p align="justify" width="20%">
                            An overview of COWP that includes the three key components of <b>Task Planner</b> (provided as prior knowledge under closed-world assumption), <b>Knowledge Acquirer</b>, and <b>Plan Monitor</b>. The <b style="color:#008000">green</b> (dashed) loop represents a plan execution process where the robot does encounter no situation, or these situations have no impact on the robot's plan execution. The <b style="color:#FFA500">orange</b> loop is activated when the robot's current (closed-world) task planner is unable to develop a plan, which activates Knowledge Acquirer to augment the task planner with additional action effects utilizing common sense
                        </p>
                    </div>

                    <br>

                    <!-- <h1 align="center">Main Idea</h1>
                    <div style="font-size:30px">
                        <p align="justify" width="20%"> COWP aims to address a PPS problem, where object properties (<b>L</b>), state mapping function (<b>Y</b>), and transition function (<b>T</b>) are unknown. Our COWP algorithm aims to compute task-motion plans to achieve task-level goals while maximizing cumulative utilities.</p>

                        <p align="justify" width="20%">
                            COWP learns <b>L</b>, <b>Y</b>, and <b>T</b> in each iteration, where the robot completes a task once in the real world and N times in simulation. In each iteration, each of <b>L</b>, <b>Y</b>, and <b>T</b> is learned under the current estimation of the other two, while a COWP agent plans at task and motion levels.
                        </p>
                    </div> -->
                    
                    <br>
                    <h1 align="center">Experiment Results</h1>

                    <table border="0" cellspacing="10" cellpadding="0" align="center">
                        <tbody>
                            <tr>
                                <td><img src="./img/fig_result1.png" width="850" height="320">
                                </td>
                            </tr>
                            <tr>
                                <td><img src="./img/fig_result2.png" width="850" height="260">
                                </td>
                            </tr>
                        </tbody>
                    </table>

                    <div style="font-size:30px">
                        <p align="justify" width="20%">
                            <b>Top:</b> Overall performances of COWP (ours) and three baseline methods under six different tasks, where the x-axis represents the task.
                            Each success rate value is an average of 150 trials. The tasks are ranked based on the performance of COWP, where the very left corresponds to its best performance.
                        </p>
                        <p align="justify" width="20%">
                            <b>Bottom:</b> Overall performances of COWP (ours) and three baseline methods under different objects, where the x-axis represents the object involved in the situation, the number beside each object is the occurrence of the object in our situation dataset, and the y-axis represents the success rate.
                            The objects are ranked based on the performance of COWP, where the very left corresponds to its best performance. 
                        </p>
                    </div>

                    
                    <!-- <center>
                        <h1>Acknowledgements</h1>
                    </center> -->
                    <!-- The webpage template was borrowed from some <a href="https://nvlabs.github.io/SPADE/">GAN folks</a>. -->
                    <!-- <div style="font-size:30px">
                        <p align="justify">
                            This work has taken place in the Autonomous Intelligent Robotics (AIR) Group at SUNY Binghamton. AIR research is supported in part by grants from the National Science Foundation (IIS-1925044 and REU Supplement), Ford Motor Company (URP Awards), OPPO (Faculty Research Award), and SUNY Research Foundation
                        </p>
                    </div> -->
                    <br><br>

</html>
